{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import WordEmbedding\n",
    "word2vectorObj = WordEmbedding.WordEmbedding()\n",
    "word2vectorObj. ReadFacebookVec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('/home/ksquare/Documents/AI/SentimentAnalysis/English/model/model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordToIndex = word2vectorObj.wordToIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def sentencesToIndices(sentences,maxLenOfSentence=45):\n",
    "        \"\"\"\n",
    "        Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "        The output shape should be such that it can be given to `Embedding()` (described in Figure 4).\n",
    "\n",
    "        Arguments:\n",
    "        sentences -- array of sentences (strings), of shape (m, 1)\n",
    "        wordToIndex -- a dictionary containing the each word mapped to its index\n",
    "        maxLenOfSentence -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this.\n",
    "\n",
    "        Returns:\n",
    "        indicesOfSentences -- array of indices corresponding to words in the sentences from X, of shape (m, maxLenOfSentence)\n",
    "        \"\"\"  \n",
    "        \n",
    "        m = sentences.shape[0]\n",
    "        indicesOfSentences = np.zeros([m,maxLenOfSentence])\n",
    "\n",
    "        for i in range(m):\n",
    "\n",
    "            # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
    "            sentenceWords = (sentences[i].lower()).split()\n",
    "\n",
    "            # Initialize j to 0\n",
    "            j = 0\n",
    "\n",
    "            # Loop over the words of sentence_words\n",
    "            for word in sentenceWords:\n",
    "                # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "\n",
    "                try:\n",
    "                    indicesOfSentences[i, j] = wordToIndex[word]\n",
    "                    j = j+1\n",
    "\n",
    "                except:\n",
    "                    kl=0\n",
    "                #j = j+1\n",
    "\n",
    "        return indicesOfSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predicton(dataset):\n",
    "    \n",
    "    sentences = np.array(dataset)\n",
    "    indecesSentences = sentencesToIndices(sentences)\n",
    "    predictions = model.predict(sentencesToIndices(sentences))\n",
    "    \n",
    "    sentimentsPred = []\n",
    "    for i in predictions:\n",
    "        sentimentsPred.append(np.argmax(i))\n",
    "        \n",
    "    return sentimentsPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.77      0.75       577\n",
      "          1       0.56      0.65      0.60       384\n",
      "          2       0.65      0.28      0.39       176\n",
      "\n",
      "avg / total       0.66      0.66      0.64      1137\n",
      "\n",
      "           0    1   2\n",
      "Class 0  446  126   5\n",
      "Class 1  112  251  21\n",
      "Class 2   56   71  49\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('/home/ksquare/Documents/AI/SentimentAnalysis/English/Elecciones2018/test120618/test12k.csv',error_bad_lines=False)\n",
    "y_pred = Predicton(dataset['text'])\n",
    "y_true = dataset['sentiment']\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1','2']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "#Confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion_matrix(y_true,y_pred),\n",
    "             columns = [class_name for class_name in target_names],\n",
    "             index = ['Class ' + class_name for class_name in target_names])\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('/home/ksquare/Documents/SentimentAnalysis/English/Datasets/Meet/training.csv',error_bad_lines=False)\n",
    "y_pred = Predicton(dataset['text'])\n",
    "y_true = dataset['sentiment']\n",
    "target_names = ['negative','neutral','positive']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "#Confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion_matrix(y_true,y_pred),\n",
    "             columns = [class_name for class_name in target_names],\n",
    "             index = ['Class ' + class_name for class_name in target_names])\n",
    "print(confusion_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('/home/ksquare/Documents/SentimentAnalysis/English/Datasets/Meet/val.csv',error_bad_lines=False)\n",
    "y_pred = Predicton(dataset['text'])\n",
    "y_true = dataset['sentiment']\n",
    "target_names = ['negative','neutral','positive']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "#Confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion_matrix(y_true,y_pred),\n",
    "             columns = [class_name for class_name in target_names],\n",
    "             index = ['Class ' + class_name for class_name in target_names])\n",
    "print(confusion_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
